{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plant_record = []\n",
    "fault_record = []\n",
    "plant_list = [1,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,21,23,24,27,28,29,30,31,32,33,34,35,36,39,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_file(plant_index,file_path):\n",
    "    train_ori_name = file_path+\"/PHM_train\"+str(plant_index)+\".csv\"\n",
    "    train_ori = pd.read_csv(train_ori_name,dtype = np.float64)\n",
    "    test_ori_name = file_path+\"PHM_test\"+str(plant_index)+\".csv\"\n",
    "    test_ori  = pd.read_csv(test_ori_name,dtype = np.float64)\n",
    "    train_label_ori_name = file_path+\"PHM_trainLabel\"+str(plant_index)+\".csv\"\n",
    "    train_label_ori = pd.read_csv( train_label_ori_name,dtype = np.float64)\n",
    "    test_label_ori_name = file_path+\"PHM_testLabel_viseble\"+str(plant_index)+\".csv\"\n",
    "    test_label_visible_ori = pd.read_csv(test_label_ori_name,dtype = np.float64)\n",
    "    \n",
    "    return train_ori,test_ori,train_label_ori,test_label_visible_ori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def remove_na_dup(dataset):\n",
    "    dataset = dataset.drop_duplicates()\n",
    "    dataset = dataset.dropna()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def onehot_encode(train_ori,test_ori):\n",
    "    train_onehot = pd.DataFrame( {\"ini\":train_ori[\"season\"]})\n",
    "    test_onehot = pd.DataFrame( {\"ini\":test_ori[\"season\"]})\n",
    "\n",
    "    for index in range(1,5):\n",
    "        train_onehot[( \"season_\"+str(index) )] = (train_ori[\"season\"] == index ).astype(int)\n",
    "        test_onehot[( \"season_\"+str(index) )] = (test_ori[\"season\"] == index ).astype(int)\n",
    "\n",
    "    for index in range(1,13):\n",
    "        train_onehot[( \"month_\"+str(index) )] = (train_ori[\"month\"] == index ).astype(int)\n",
    "        test_onehot[( \"month_\"+str(index) )] = (test_ori[\"month\"] == index ).astype(int)\n",
    "\n",
    "    for index in range(1,8):\n",
    "        train_onehot[( \"wday_\"+str(index) )] = (train_ori[\"wday\"] == index ).astype(int)\n",
    "        test_onehot[( \"wday_\"+str(index) )] = (test_ori[\"wday\"] == index ).astype(int)\n",
    "\n",
    "    for index in range(1,25):\n",
    "        train_onehot[( \"hour_\"+str(index) )] = (train_ori[\"hour\"] == index ).astype(int)\n",
    "        test_onehot[( \"hour_\"+str(index) )] = (test_ori[\"hour\"] == index ).astype(int)\n",
    "        \n",
    "    train_onehot = train_onehot.drop(\"ini\",1)\n",
    "    test_onehot = test_onehot.drop(\"ini\",1)\n",
    "    return train_onehot,test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def standardize(dataset_train,dataset_test):\n",
    "    b = (dataset_test - dataset_train.mean())/dataset_train.std()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def combine_addzero_feature(sensor,onehot,width):\n",
    "    dataset = pd.concat([onehot,sensor],axis = 1)\n",
    "    dataset.columns.values\n",
    "    ##add padding\n",
    "    for index in range( 13**2-dataset.shape[1] ):\n",
    "        dataset[(\"zero_\"+str(index))] = 0\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_laged_feature(dataset,dataset_ori,section):\n",
    "    train_laged = dataset[ section:(dataset.shape[0]-section)]\n",
    "    train_laged.index = range(train_laged.shape[0])\n",
    "    train_laged_time = dataset_ori.iloc[ section:(dataset.shape[0]-section),0 ]\n",
    "    train_laged_time.index = range(train_laged_time.shape[0])\n",
    "\n",
    "\n",
    "    \n",
    "        ##before section\n",
    "    for index in range(section):\n",
    "        add_lag = dataset[index:(dataset.shape[0]-section*2+index)]\n",
    "        add_lag.columns = add_lag.columns.values+\"_-\"+str(index)\n",
    "        add_lag.index = range(add_lag.shape[0])\n",
    "        train_laged = pd.concat([train_laged, add_lag],axis = 1)\n",
    "\n",
    "\n",
    "        ##after section\n",
    "    for index in range(section):\n",
    "        add_lag = dataset[(section+index):(dataset.shape[0]-section+index)]\n",
    "        add_lag.columns = add_lag.columns.values+\"_+\"+str(index)\n",
    "        add_lag.index = range(add_lag.shape[0])\n",
    "        train_laged = pd.concat([train_laged, add_lag],axis = 1)\n",
    "\n",
    "            ##combine\n",
    "    train_c = pd.concat([train_laged_time,train_laged],axis = 1)\n",
    "\n",
    "\n",
    "    return train_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def add_label(dataset,dataset_fault):\n",
    "    ##add label\n",
    "    dataset[\"start_label\"] = 0\n",
    "    for index in range( dataset_fault.shape[0] ):\n",
    "        label_v = range( int(dataset_fault[\"startTime\"][index]-4) ,int(dataset_fault[\"startTime\"][index]+5) )    \n",
    "        dataset.loc[dataset.time.isin(label_v),'start_label'] = 1\n",
    "\n",
    "    return dataset        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##add test visible fault to train set\n",
    "def add_visible_to_train(train_sub,test_sub):  \n",
    "    add_test = test_sub[test_sub.start_label == 1]\n",
    "    train_sub_add = pd.concat([train_sub,add_test],axis = 0,ignore_index = True)\n",
    "    train_sub_add = train_sub_add.sort_values([\"time\"])\n",
    "    return train_sub_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##random down sampling\n",
    "def random_down_sampling(train_sub_add):\n",
    "    train_sub_0 = train_sub_add[train_sub_add.start_label == 0]\n",
    "    train_sub_0.index = range(train_sub_0.shape[0])\n",
    "    train_sub_1 = train_sub_add[train_sub_add.start_label == 1]\n",
    "    train_sub_1.index = range(train_sub_1.shape[0])\n",
    "    train_sub_0 = train_sub_0.iloc[np.random.choice(train_sub_0.shape[0], train_sub_1.shape[0], replace=True),:]\n",
    "    train_set = pd.concat([train_sub_1,train_sub_0],axis = 0,ignore_index = True)\n",
    "    train_set = train_set.sort_values([\"time\"])\n",
    "    train_set.index = range(train_set.shape[0])\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "##main function\n",
    "def do_preprocess(width,section,read_file_path,save_file_path) :\n",
    "    count = 0\n",
    "    for plant_index in plant_list:\n",
    "        print(\"plant_index: %s  total: %s\"%(count,len(plant_list)))\n",
    "        count = count+1\n",
    "        ##for loop\n",
    "        train_ori,test_ori,train_label_ori,test_label_visible_ori = read_file(plant_index,read_file_path)\n",
    "        train_ori = remove_na_dup(train_ori)\n",
    "        test_ori = remove_na_dup(test_ori)\n",
    "        train_sensor = train_ori.drop([\"time\",\"year\",\"season\",\"month\",\"wday\",\"hour\"],1)\n",
    "        test_sensor = test_ori.drop(test_ori.columns[:6],1)\n",
    "        train_onehot,test_onehot = onehot_encode(train_ori,test_ori)\n",
    "        test_sensor = standardize(train_sensor,test_sensor)\n",
    "        train_sensor = standardize(train_sensor,train_sensor)\n",
    "        train_basic = combine_addzero_feature(train_sensor,train_onehot,width)\n",
    "        test_basic = combine_addzero_feature(test_sensor,test_onehot,width)\n",
    "        train_combine = add_laged_feature(train_basic,train_ori,section)\n",
    "        test_combine = add_laged_feature(test_basic,test_ori,section)\n",
    "        #different faults\n",
    "        for fault_index in train_label_ori[\"fault\"].unique().astype(int):\n",
    "            print(\"fault: %s\"%fault_index)\n",
    "            ##for loop\n",
    "            train_sub = train_combine\n",
    "            test_sub = test_combine\n",
    "            train_sub_fault = train_label_ori[ train_label_ori[\"fault\"] == fault_index ]\n",
    "            train_sub_fault.index = range(train_sub_fault.shape[0])\n",
    "            test_sub_fault = test_label_visible_ori[test_label_visible_ori[\"fault\"] == fault_index ]\n",
    "            test_sub_fault.index = range(test_sub_fault.shape[0])\n",
    "            train_sub = add_label(train_sub,train_sub_fault)\n",
    "            test_sub = add_label(test_sub,test_sub_fault)\n",
    "            train_sub_add = add_visible_to_train(train_sub,test_sub)\n",
    "            test_set =  test_sub[test_sub.start_label == 0]\n",
    "            train_set = train_sub_add\n",
    "\n",
    "            ##record plant and fault\n",
    "            plant_record.append(plant_index)\n",
    "            fault_record.append(fault_index)\n",
    "\n",
    "            ##write csv\n",
    "            train_set_name = save_file_path+\"/trainset\"+str(plant_index)+\"_fault\"+str(fault_index)+\".csv\"\n",
    "            train_set.to_csv(train_set_name,index = False,sep = \",\" )\n",
    "\n",
    "            test_set_name = save_file_path+\"/testset\"+str(plant_index)+\"_fault\"+str(fault_index)+\".csv\"\n",
    "            test_set.to_csv(test_set_name,index = False,sep = \",\" )\n",
    "            \n",
    "    f_name = save_file_path + \"plant_list.csv\"\n",
    "    f = open( f_name,\"w\")\n",
    "    for index in range( (len(plant_record)-1) ):\n",
    "        f.write(str(plant_record[index])+\",\")\n",
    "    f.write(str(plant_record[-1]))\n",
    "    f.close()\n",
    "    \n",
    "    f_name = save_file_path + \"fault_list.csv\"\n",
    "    f = open(f_name,\"w\")\n",
    "    for index in range( (len(fault_record)-1) ):\n",
    "        f.write(str(fault_record[index])+\",\")\n",
    "    f.write(str(fault_record[-1]))\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plant_index: 0  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 3\n",
      "fault: 4\n",
      "fault: 5\n",
      "plant_index: 1  total: 31\n",
      "fault: 1\n",
      "fault: 4\n",
      "fault: 2\n",
      "fault: 5\n",
      "plant_index: 2  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 4\n",
      "fault: 3\n",
      "fault: 5\n",
      "plant_index: 3  total: 31\n",
      "fault: 1\n",
      "fault: 4\n",
      "fault: 2\n",
      "fault: 3\n",
      "plant_index: 4  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 3\n",
      "fault: 4\n",
      "plant_index: 5  total: 31\n",
      "fault: 4\n",
      "fault: 3\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 5\n",
      "plant_index: 6  total: 31\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 5\n",
      "fault: 4\n",
      "fault: 3\n",
      "plant_index: 7  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 5\n",
      "plant_index: 8  total: 31\n",
      "fault: 1\n",
      "fault: 5\n",
      "fault: 4\n",
      "fault: 3\n",
      "plant_index: 9  total: 31\n",
      "fault: 1\n",
      "fault: 4\n",
      "plant_index: 10  total: 31\n",
      "fault: 1\n",
      "fault: 3\n",
      "fault: 2\n",
      "fault: 4\n",
      "plant_index: 11  total: 31\n",
      "fault: 4\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 5\n",
      "fault: 3\n",
      "plant_index: 12  total: 31\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 4\n",
      "fault: 5\n",
      "fault: 3\n",
      "plant_index: 13  total: 31\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 4\n",
      "fault: 3\n",
      "fault: 5\n",
      "plant_index: 14  total: 31\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 5\n",
      "fault: 4\n",
      "fault: 3\n",
      "plant_index: 15  total: 31\n",
      "fault: 2\n",
      "fault: 3\n",
      "fault: 1\n",
      "fault: 4\n",
      "fault: 5\n",
      "plant_index: 16  total: 31\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 4\n",
      "plant_index: 17  total: 31\n",
      "fault: 1\n",
      "fault: 4\n",
      "fault: 5\n",
      "plant_index: 18  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 4\n",
      "fault: 3\n",
      "plant_index: 19  total: 31\n",
      "fault: 1\n",
      "fault: 4\n",
      "fault: 2\n",
      "fault: 3\n",
      "plant_index: 20  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 3\n",
      "fault: 4\n",
      "fault: 5\n",
      "plant_index: 21  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 3\n",
      "fault: 4\n",
      "plant_index: 22  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 5\n",
      "fault: 4\n",
      "fault: 3\n",
      "plant_index: 23  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "plant_index: 24  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 4\n",
      "fault: 5\n",
      "fault: 3\n",
      "plant_index: 25  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 3\n",
      "fault: 4\n",
      "fault: 5\n",
      "plant_index: 26  total: 31\n",
      "fault: 1\n",
      "fault: 5\n",
      "fault: 2\n",
      "fault: 4\n",
      "fault: 3\n",
      "plant_index: 27  total: 31\n",
      "fault: 1\n",
      "fault: 2\n",
      "fault: 5\n",
      "fault: 4\n",
      "fault: 3\n",
      "plant_index: 28  total: 31\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 3\n",
      "fault: 4\n",
      "fault: 5\n",
      "plant_index: 29  total: 31\n",
      "fault: 4\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 5\n",
      "fault: 3\n",
      "plant_index: 30  total: 31\n",
      "fault: 2\n",
      "fault: 1\n",
      "fault: 3\n",
      "fault: 4\n",
      "fault: 5\n"
     ]
    }
   ],
   "source": [
    "##parameters setting\n",
    "width = 13\n",
    "section = 4\n",
    "read_file_path = \"/media/joeytu/82F6C88FF6C8853F/PHM2017/PHM_rawdata/\"\n",
    "save_file_path = \"/media/joeytu/82F6C88FF6C8853F/PHM2017/PHM_nosample/file/start\"\n",
    "\n",
    "##do_preprocess\n",
    "do_preprocess(width,section,read_file_path,save_file_path) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
